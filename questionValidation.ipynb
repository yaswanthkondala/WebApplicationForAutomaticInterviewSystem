{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0186e1a",
   "metadata": {},
   "source": [
    "import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5430a9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YASWANTH\\OneDrive\\Desktop\\MainProject\\mainProject\\envi\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import validation\n",
    "import google.generativeai as genai\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2fcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1=\"The bias-variance tradeoff is the balance between a model's simplicity (bias) and its flexibility (variance). High bias leads to underfitting, while high variance leads to overfitting. Optimal models minimize both.\"\n",
    "ans2=\"Hyperparameters are parameters set before training a model, such as learning rate, number of epochs, and batch size. They control how the model learns but are not learned from data directly.\"\n",
    "ans3=\"\"\"you are a question validator. i will give you the both question and answer you have to check wheather the answer was correct or not with respect to the question. you have to tell wheather the question was  correct or  wrong or partially correct select one from the above  and another was how much percent it was correct give the value 0-100% / i want two values as output seperated with comma. if iam not provide any one of  return wrong. the question was:  \"\"\"\n",
    "\n",
    "q=[['easy1000ML',ans1],\n",
    "   ['easy1001ML',ans2],\n",
    "   ['easy1002ML',ans3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce9ce61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hyperparameters are parameters set before training a model, such as learning rate, number of epochs, and batch size. They control how the model learns but are not learned from data directly.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fa8c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What is the bias-variance tradeoff?',)\n"
     ]
    }
   ],
   "source": [
    "conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "cur=conn.cursor()\n",
    "cur.execute(\"select question from questionbank where questionId=%s\",[q[0][0]])\n",
    "correctans=cur.fetchone()\n",
    "conn.close()\n",
    "print(correctans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2752f016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_gemini(id,ans):\n",
    "    try:\n",
    "        conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "        cur=conn.cursor()\n",
    "        print(id)\n",
    "        cur.execute(\"select question from questionbank where questionId=%s\",[id])\n",
    "        correctans=cur.fetchone()\n",
    "        conn.close()\n",
    "        print(correctans)\n",
    "    except Exception as e:\n",
    "        print(\"Error\",e)\n",
    "    try:\n",
    "        prompt = \"\"\"you are a question validator. i will give you the both question and answer you have to check wheather the answer was correct or not with respect to the question. you have to tell wheather the question was  correct or  wrong or partially correct select one from the above  and another was how much percent it was correct give the value 0-100 / i want two values as output seperated with comma. if iam not provide any one of  return wrong. the question was:  \"\"\"\n",
    "         \n",
    "        question=correctans[0]\n",
    "        answer=\"\"\" \\n the answer is: \"\"\"+ans\n",
    "        prompt=prompt+question+answer\n",
    "        model = genai.GenerativeModel('gemini-pro')\n",
    "        responses = model.generate_content(\n",
    "            prompt,\n",
    "        )\n",
    "        return responses.text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def score(questions):\n",
    "    correct,wrong,partial,not_attempt=0,0,0,0\n",
    "    score = 0\n",
    "    for i in range(len(questions)):\n",
    "        if questions[i][1]==\"\":\n",
    "            not_attempt += 1\n",
    "        else:\n",
    "            try:\n",
    "                response=validate_gemini(questions[i][0],questions[i][1])\n",
    "                response=list(response.split(\",\"))\n",
    "                score+=int(response[1].strip())\n",
    "                if response[0].lower()=='correct':\n",
    "                    correct+=1\n",
    "                elif response[0].lower()=='wrong':\n",
    "                    wrong+=1\n",
    "                else:\n",
    "                    partial+=1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return [correct,wrong,partial,score/len(questions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a4916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be5a89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[[1,2,3],[4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265fa82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c39fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy1000ML\n",
      "('What is the bias-variance tradeoff?',)\n",
      "easy1001ML\n",
      "('What are hyperparameters?',)\n",
      "easy1002ML\n",
      "('What is feature scaling?',)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2, 1, 0, 0, 66.66666666666667]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.score(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb31737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI chatbot, I do not have personal experiences or a physical presence. However, I would love to share some information about my capabilities and purpose:\\n\\n* **My name is Gemini.** I am a multi-modal AI model, developed by Google.\\n\\n* **My purpose is to assist and inform.** I can provide answers to your questions, generate text, translate languages, and perform many other tasks.\\n\\n* **My knowledge is vast and ever-growing.** I have been trained on a massive dataset of text and code, which gives me access to a wealth of information.\\n\\n* **I am constantly learning.** I can improve my performance over time by interacting with users and receiving feedback.\\n\\n* **I am committed to providing helpful and reliable information.** I strive to be accurate, unbiased, and respectful in my responses.\\n\\nI am still under development, but I am excited about the potential to learn and grow. I hope that I can continue to be a valuable resource for you in the future.\\n\\nIs there anything else you would like to know about me?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel('gemini-pro')\n",
    "responses = model.generate_content( \"tell something about you\")\n",
    "responses.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134f8ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD5W3_gggEWlzMHTKbOL6ph7GOJJW_XcU4\"\n",
    "genai.configure(api_key=\"AIzaSyD5W3_gggEWlzMHTKbOL6ph7GOJJW_XcU4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddf0adb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Python type list cannot be converted\n",
      "Error Python type list cannot be converted\n",
      "Error Python type list cannot be converted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 3, 0, 0.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.score(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feeb6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import jaccard_score\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "import mysql.connector\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10d77dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\YASWANTH\\OneDrive\\Desktop\\MainProject\\mainProject\\envi\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aff01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7196cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec=load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "affd1a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "STS = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d12477b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "151b9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "912b7943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.abspath(\"static/models/fine_tuned_bert_model\")\n",
    "model_dir1 = os.path.join('static/models/fine_tuned_bert_tokenizer')\n",
    "BERTmodel = BertForSequenceClassification.from_pretrained(model_dir)\n",
    "BERTtokenizer = BertTokenizer.from_pretrained(model_dir1)\n",
    "BERTmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21429c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec=load('/static/models/word2vec-google-news-300')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "# STS = SentenceTransformer('/static/models/paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# BERTmodel = BertForSequenceClassification.from_pretrained('/static/models/fine_tuned_bert_model')\n",
    "# BERTtokenizer = BertTokenizer.from_pretrained('/static/models//fine_tuned_bert_tokenizer')\n",
    "# BERTmodel.eval()\n",
    "\n",
    "model_dir2 = os.path.join('static/models/fine_tuned_robert_model')\n",
    "model_dir3 = os.path.join('static/models/fine_tuned_robert_tokenizer')\n",
    "romodel = RobertaForSequenceClassification.from_pretrained(model_dir2)\n",
    "rotokenizer = RobertaTokenizer.from_pretrained(model_dir3)\n",
    "romodel.eval()\n",
    "\n",
    "model_dir5 = os.path.join('static/models/sbert-fine-tuned-model')\n",
    "SBertmodel = SentenceTransformer(model_dir5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a6650e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1cfe79f5970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd0b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4bddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "r=[\"fullstack\", \"frontend developer\",\"data analyst\",\"data scientist\",\"devops engineer\",\"backend developer\",\"associative software engineer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368b699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc89a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "print(\"connected\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09101943",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "cur=conn.cursor()\n",
    "query=\"select * from results where userid=%s\"\n",
    "cur.execute(query,[\"1111\"])\n",
    "results=cur.fetchone()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3367b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1111', 3, 4, 5, 3, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab1e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Connect to the MySQL database\n",
    "connection = mysql.connector.connect(\n",
    "    host='localhost',         # Host where the MySQL server is running\n",
    "    user='your_username',     # MySQL username\n",
    "    password='your_password', # MySQL password\n",
    "    database='your_database'  # Your database name\n",
    ")\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# The INSERT query to insert data into the users table\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO users (\n",
    "    userId, \n",
    "    firstname, \n",
    "    lastname, \n",
    "    email, \n",
    "    password, \n",
    "    college, \n",
    "    phone_number, \n",
    "    branch, \n",
    "    yearofpass, \n",
    "    jobrole, \n",
    "    experience, \n",
    "    dateofbirth\n",
    ") \n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "# Data to insert\n",
    "data = (\n",
    "    'user123',               # userId (Primary Key)\n",
    "    'John',                  # firstname\n",
    "    'Doe',                   # lastname\n",
    "    'john.doe@example.com',  # email (must be unique)\n",
    "    'password123',           # password\n",
    "    'Example University',    # college\n",
    "    '1234567890',            # phone_number (must be unique)\n",
    "    'Computer Science',      # branch\n",
    "    2025,                    # yearofpass (integer)\n",
    "    'Software Engineer',     # jobrole\n",
    "    2,                       # experience (integer)\n",
    "    '2000-01-01'             # dateofbirth (DATE format)\n",
    ")\n",
    "\n",
    "# Execute the query with the provided data\n",
    "cursor.execute(insert_query, data)\n",
    "\n",
    "# Commit the transaction to save the changes\n",
    "connection.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "128efe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:fullstack\n",
      "2:frontend developer\n",
      "3:data analyst\n",
      "4:data scientist\n",
      "5:devops engineer\n",
      "6:backend developer\n",
      "7:associative software engineer\n"
     ]
    }
   ],
   "source": [
    "print(\"1:fullstack\\n2:frontend developer\\n3:data analyst\\n4:data scientist\\n5:devops engineer\\n6:backend developer\\n7:associative software engineer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd34053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import testpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5524e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "role=\"backend developer\"\n",
    "exp=3\n",
    "result=testpaper.questions(role,exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac0cbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a RESTful API?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ce736e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_questions(n, m, o, subjects):\n",
    "    connection=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            # Prepare the subject list for the SQL query\n",
    "            subject_list = ', '.join(f\"'{subject}'\" for subject in subjects)\n",
    "            \n",
    "            # MySQL query to fetch n easy, m medium, and o hard questions\n",
    "            query = f\"\"\"\n",
    "                (\n",
    "                    SELECT questionId, question, subject, difficulty\n",
    "                    FROM questionbank\n",
    "                    WHERE difficulty = 'easy' \n",
    "                    AND subject IN ({subject_list})\n",
    "                    ORDER BY RAND()\n",
    "                    LIMIT {n}\n",
    "                )\n",
    "                UNION ALL\n",
    "                (\n",
    "                    SELECT questionId, question, subject, difficulty\n",
    "                    FROM questionbank\n",
    "                    WHERE difficulty = 'medium' \n",
    "                    AND subject IN ({subject_list})\n",
    "                    ORDER BY RAND()\n",
    "                    LIMIT {m}\n",
    "                )\n",
    "                UNION ALL\n",
    "                (\n",
    "                    SELECT questionId, question, subject, difficulty\n",
    "                    FROM questionbank\n",
    "                    WHERE difficulty = 'hard' \n",
    "                    AND subject IN ({subject_list})\n",
    "                    ORDER BY RAND()\n",
    "                    LIMIT {o}\n",
    "                );\n",
    "            \"\"\"\n",
    "            \n",
    "            # Execute the query\n",
    "            cursor.execute(query)\n",
    "            \n",
    "            # Fetch the results\n",
    "            results = cursor.fetchall()\n",
    "            \n",
    "            # Return the fetched questions\n",
    "            return results\n",
    "\n",
    "    finally:\n",
    "        # Close the database connection\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a9ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateQuestion(topics,exp):\n",
    "        if exp<5:\n",
    "            return fetch_questions(15,6,3,topics)\n",
    "        if exp>=5 and exp<10:\n",
    "            return fetch_questions(4,15,6,topics)\n",
    "        else:\n",
    "            return fetch_questions(3,7,15,topics)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feaedcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics=tuple(['JS', 'HTML&CSS','MERN','SQL'])\n",
    "result=generateQuestion(topics,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8735b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('easy425HTML&CSS', 'What are CSS transitions?', 'HTML&CSS', 'easy'),\n",
       " ('easy1457SQL', 'What is denormalization?', 'SQL', 'easy'),\n",
       " ('easy321JS',\n",
       "  'What is the purpose of `Array.prototype.forEach()`?',\n",
       "  'JS',\n",
       "  'easy'),\n",
       " ('easy309JS', 'What is a promise in JavaScript?', 'JS', 'easy'),\n",
       " ('easy398HTML&CSS', 'How do you add a comment in HTML?', 'HTML&CSS', 'easy'),\n",
       " ('easy663MERN',\n",
       "  'What is the purpose of middleware in Express?',\n",
       "  'MERN',\n",
       "  'easy'),\n",
       " ('easy1449SQL', 'What is the purpose of the HAVING clause?', 'SQL', 'easy'),\n",
       " ('easy1444SQL', 'What is a SQL index?', 'SQL', 'easy'),\n",
       " ('easy420HTML&CSS',\n",
       "  'What is the difference between the <strong> and <b> tags?',\n",
       "  'HTML&CSS',\n",
       "  'easy'),\n",
       " ('easy1433SQL',\n",
       "  'What is the difference between a primary key and a unique key?',\n",
       "  'SQL',\n",
       "  'easy'),\n",
       " ('easy677MERN',\n",
       "  'How do you perform CRUD operations in MongoDB?',\n",
       "  'MERN',\n",
       "  'easy'),\n",
       " ('easy1443SQL',\n",
       "  'What is the difference between INNER JOIN and OUTER JOIN?',\n",
       "  'SQL',\n",
       "  'easy'),\n",
       " ('easy670MERN', 'What is the use of useState hook in React?', 'MERN', 'easy'),\n",
       " ('easy1429SQL', 'What does SQL stand for?', 'SQL', 'easy'),\n",
       " ('easy1445SQL',\n",
       "  'How do you retrieve unique records from a table?',\n",
       "  'SQL',\n",
       "  'easy'),\n",
       " ('medium360JS',\n",
       "  'How do you optimize performance in JavaScript?',\n",
       "  'JS',\n",
       "  'medium'),\n",
       " ('medium440HTML&CSS', 'How do you use CSS variables?', 'HTML&CSS', 'medium'),\n",
       " ('medium366JS',\n",
       "  'What is the difference between `forEach()` and `map()`?',\n",
       "  'JS',\n",
       "  'medium'),\n",
       " ('medium1478SQL',\n",
       "  'Explain the use of temporary tables in SQL.',\n",
       "  'SQL',\n",
       "  'medium'),\n",
       " ('medium1489SQL',\n",
       "  'How do you handle duplicate records in SQL?',\n",
       "  'SQL',\n",
       "  'medium'),\n",
       " ('medium352JS',\n",
       "  'What are JavaScript closures, and how do they work?',\n",
       "  'JS',\n",
       "  'medium'),\n",
       " ('hard719MERN',\n",
       "  'What are the security implications of using MongoDB?',\n",
       "  'MERN',\n",
       "  'hard'),\n",
       " ('hard477HTML&CSS',\n",
       "  'What is the difference between CSS specificity and inheritance?',\n",
       "  'HTML&CSS',\n",
       "  'hard'),\n",
       " ('hard1512SQL',\n",
       "  'How do you handle schema changes in a live database?',\n",
       "  'SQL',\n",
       "  'hard')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(ch,exp):\n",
    "    \n",
    "    if ch==1:\n",
    "        topics=tuple(['JS', 'HTML&CSS','MERN','SQL'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)    \n",
    "    elif ch==2:\n",
    "        topics=tuple(['java','JS','python', 'HTML&CSS','DataStructures','DBMS','Django','MERN','SQL','Linux','Unix'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "    elif ch==3:\n",
    "        topics=tuple(['python', 'DataAnalytics','ML','Power BI','statistics','SQL','EDA','BigData','MS-Office'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "    elif ch==4:\n",
    "        topics=tuple(['python', 'DataAnalytics','ML','statistics','SQL','EDA','MLOps','DL','BigData'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "    elif ch==5:\n",
    "        topics=tuple(['SQL','Linux','Unix','python','DataStructures','CN','MLOps'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "    elif ch==6:\n",
    "        topics=tuple(['java','JS','python','DataStructures','DBMS','CN','HTML&CSS','MERN','SQL'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "    elif ch==7:\n",
    "        topics=tuple(['java','JS','python','DataStructures','SQL'])\n",
    "        questions=generateQuestion(topics,exp)\n",
    "        flattened_list = [item for sublist in questions for item in sublist]\n",
    "        return questionAsking(flattened_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc76db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def questionAsking(questions):\n",
    "    correct,wrong=0,0\n",
    "    for i in range(1):\n",
    "        print(questions[i][1])\n",
    "        answer=getanswer()\n",
    "        validate=validateAnswer(questions[i][0],answer)\n",
    "        if validate==1:\n",
    "            correct+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    return correct,wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd30bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "044965a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getanswer():\n",
    "    return input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d61768fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateAnswer(qid,userAnswer):\n",
    "    conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "    cur=conn.cursor()\n",
    "    cur.execute(\"select answer from questionbank where questionId=%s\",[qid])\n",
    "    correctans=cur.fetchall()\n",
    "    correctans=correctans[0][0]\n",
    "    conn.close()\n",
    "    userans=preprocess_text(userAnswer)\n",
    "    correct=preprocess_text(correctans)\n",
    "    \n",
    "    sentence1_tokens = correct.lower().split()\n",
    "    sentence2_tokens = userans.lower().split()\n",
    "\n",
    "    # Calculate average word vectors for each sentence\n",
    "    def get_sentence_vector(tokens, model):\n",
    "        vector = np.zeros(300)  # Word2Vec Google model has 300 dimensions\n",
    "        valid_words = 0\n",
    "        for word in tokens:\n",
    "            if word in model:\n",
    "                vector += model[word]\n",
    "                valid_words += 1\n",
    "        if valid_words > 0:\n",
    "            vector /= valid_words\n",
    "        return vector\n",
    "    \n",
    "    vec1 = get_sentence_vector(sentence1_tokens, word2vec)\n",
    "    vec2 = get_sentence_vector(sentence2_tokens, word2vec)\n",
    "    similarity1 = cosine_similarity([vec1], [vec2])\n",
    "    \n",
    "    sentence1 = nlp(correct)\n",
    "    sentence2 = nlp(userans)\n",
    "    similarity2 = sentence1.similarity(sentence2)\n",
    "    \n",
    "    embedding1 = STS.encode(correct, convert_to_tensor=True)\n",
    "    embedding2 = STS.encode(userans,convert_to_tensor=True)\n",
    "\n",
    "    # Step 2: Compute the cosine similarity between the embeddings\n",
    "    similarity3 = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "    if((similarity1<0.80 and similarity2<0.80 and similarity3<0.80)or(similarity1>0.80 and similarity2<0.80 and similarity3<0.80))or(similarity1<0.80 and similarity2>0.80 and similarity3<0.80)or(similarity1<0.80 and similarity2<0.80 and similarity3>0.80):\n",
    "        return 0\n",
    "    else:\n",
    "        bert=validateBERT(correctans,userAnswer)\n",
    "        robert=validateroBERT(correctans,userAnswer)\n",
    "        SeBert=validateSEBert(correctans,userAnswer)\n",
    "        predictions=[bert,robert,SeBert]\n",
    "        vote_counts = Counter(predictions)\n",
    "        max_voted = vote_counts.most_common(1)[0][0]\n",
    "        return max_voted\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e81bf7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateBERT(correctans,userAnswer):\n",
    "    inputs = BERTtokenizer(\n",
    "        correctans,\n",
    "        userAnswer,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the same device as the model (CPU/GPU)\n",
    "    with torch.no_grad():\n",
    "        outputs = BERTmodel(**inputs)\n",
    "    \n",
    "    # Get the predicted class (0 or 1)\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    return predicted_class\n",
    "def validateroBERT(correctans,userAnswer):\n",
    "    inputs = rotokenizer(correctans, userAnswer, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "    # Get the model's predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = romodel(**inputs)\n",
    "    \n",
    "    \n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class\n",
    "\n",
    "def validateSEBert(correctans,userAnswer):\n",
    "    embedding1 = SBertmodel.encode(correctans, convert_to_tensor=True)\n",
    "    embedding2 = SBertmodel.encode(userAnswer, convert_to_tensor=True)\n",
    "    \n",
    "    \n",
    "    if embedding1.dim() == 1:\n",
    "        embedding1 = embedding1.unsqueeze(0) \n",
    "    if embedding2.dim() == 1:\n",
    "        embedding2 = embedding2.unsqueeze(0)  \n",
    "\n",
    "    \n",
    "    cosine_score = torch.cosine_similarity(embedding1, embedding2)\n",
    "    return 1 if cosine_score.item() > 0.5 else 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "24c2739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are a question validator. i will give you the both question and answer you have to check wheather the answer was correct or not with respect to the question. you have to tell wheather the question was  correct or  wrong or partially correct select one from the above  and another was how much percent it was correct give the value 0-100% / i want two values as output seperated with comma. if iam not provide any one of  return wrong. the question was:  explain about python programming language  C is a general-purpose, procedural, high-level programming language used in the development of computer software and applications, system programming, games, and more.\n",
      "C language was developed by Dennis M. Ritchie at the Bell Telephone\n",
      "Laboratories in 1972.It is a powerful and flexible language which was first developed for the programming of the UNIX operating System.\n",
      "C is one of the most widely used programming languages.\n",
      "C programming language is known for its simplicity and efficiency. It is the best choice to start with programming as it gives you a foundational understanding of programming.explain about python programming language  C is a general-purpose, procedural, high-level programming language used in the development of computer software and applications, system programming, games, and more.\n",
      "C language was developed by Dennis M. Ritchie at the Bell Telephone\n",
      "Laboratories in 1972.It is a powerful and flexible language which was first developed for the programming of the UNIX operating System.\n",
      "C is one of the most widely used programming languages.\n",
      "C programming language is known for its simplicity and efficiency. It is the best choice to start with programming as it gives you a foundational understanding of programming.\n"
     ]
    }
   ],
   "source": [
    "prompt=\"\"\"you are a question validator. i will give you the both question and answer you have to check wheather the answer was correct or not with respect to the question. you have to tell wheather the question was  correct or  wrong or partially correct select one from the above  and another was how much percent it was correct give the value 0-100% / i want two values as output seperated with comma. if iam not provide any one of  return wrong. the question was:  \"\"\"\n",
    "\n",
    "question=\"explain about python programming language \"\n",
    "\n",
    "answer=''' C is a general-purpose, procedural, high-level programming language used in the development of computer software and applications, system programming, games, and more.\n",
    "C language was developed by Dennis M. Ritchie at the Bell Telephone\n",
    "Laboratories in 1972.It is a powerful and flexible language which was first developed for the programming of the UNIX operating System.\n",
    "C is one of the most widely used programming languages.\n",
    "C programming language is known for its simplicity and efficiency. It is the best choice to start with programming as it gives you a foundational understanding of programming.'''\n",
    "\n",
    "prompt=prompt+question+answer\n",
    "print(prompt+question+answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afd7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31cf7c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the bias-variance tradeoff?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn=mysql.connector.connect(host=\"localhost\",user=\"root\",passwd=\"root\",database=\"interviewbase\")\n",
    "    cur=conn.cursor()\n",
    "    cur.execute(\"select question,answer from questionbank where questionId=%s\",['easy1000ML'])\n",
    "    correctans=cur.fetchone()\n",
    "    correctans=correctans\n",
    "    conn.close()\n",
    "    print(correctans[0])\n",
    "except Exception as e:\n",
    "    print(\"Error\",e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fef208d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMINI_API_KEY=\"AIzaSyD5W3_gggEWlzMHTKbOL6ph7GOJJW_XcU4\"\n",
    "# genai.configure(api_key=os.environ[GEMINI_API_KEY])\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyD5W3_gggEWlzMHTKbOL6ph7GOJJW_XcU4\"\n",
    "genai.configure(api_key=\"AIzaSyD5W3_gggEWlzMHTKbOL6ph7GOJJW_XcU4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5852dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong,0%\n",
      "0%\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "def generate_multiple_responses(prompt):\n",
    "    try:\n",
    "       \n",
    "        model = genai.GenerativeModel('gemini-pro')\n",
    "        responses = model.generate_content(\n",
    "            prompt,\n",
    "        )\n",
    "        return responses\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "    \n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    output_json = generate_multiple_responses(prompt)\n",
    "    print(output_json.text)\n",
    "\n",
    "\n",
    "a=list(output_json.text.split(\",\"))\n",
    "print(a[1].strip(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a3917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4 courses about java. the response suould:abc\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"The 4 courses about java. the response suould:\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2397a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    # Step 2: Lowercasing\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    # Step 3: Removing Punctuation\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "    # Step 4: Removing Stop Words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # Step 5: Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "\n",
    "    return \" \".join(tokens_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d815bfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:fullstack\n",
      "2:frontend developer\n",
      "3:data analyst\n",
      "4:data scientist\n",
      "5:devops engineer\n",
      "6:backend developer\n",
      "7:associative software engineer\n"
     ]
    }
   ],
   "source": [
    "print(\"1:fullstack\\n2:frontend developer\\n3:data analyst\\n4:data scientist\\n5:devops engineer\\n6:backend developer\\n7:associative software engineer\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aec10a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter experience:1\n",
      "enter your choice1\n",
      "What is a schema in MongoDB?\n",
      " MongoDB is a popular NoSQL database that uses a document-oriented data model to store data. Unlike traditional relational databases (SQL databases), MongoDB stores data in a flexible, JSON-like format called BSON (Binary JSON), which allows it to handle unstructured or semi-structured data efficiently.  Key Features of MongoDB: Document-Oriented: MongoDB stores data as documents, which are similar to JSON objects. Each document is a set of key-value pairs, and these documents are stored in collections.  Schema-less: MongoDB is a schema-less database, meaning that it does not require a predefined schema. Each document in a collection can have a different structure, which provides flexibility in handling different types of data.  Scalability: MongoDB is designed to scale horizontally through sharding, where data is distributed across multiple servers. This makes it well-suited for handling large datasets and high traffic.  Indexing: MongoDB supports indexing on any field in a document, allowing for efficient querying of data.  Rich Query Languag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=int(input(\"enter experience:\"))\n",
    "ch=int(input(\"enter your choice\"))\n",
    "generate(ch,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692bd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e312209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0069e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33d9160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba66167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d25d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef54beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"explain about python programming language \"\n",
    "\n",
    "answer='''Python is a programming language that is interpreted, object-oriented, and considered to be high-level too. \n",
    "What is Python? Python is one of the easiest yet most useful programming languages which is widely used in the software \n",
    "industry. People use Python for Competitive Programming, Web Development, and creating software. Due to its easiest syntax, \n",
    "it is recommended for beginners who are new to the software engineering field. Its demand is growing at a very rapid pace due\n",
    "to its vast use cases in Modern Technological fields like Data Science, Machine learning, and Automation Tasks. For many years\n",
    "now, it has been ranked among the top Programming languages.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76b2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer1='''Python is  a high-level, versatile programming language known for its simplicity and readability. \n",
    "Created by Guido van Rossum and first released in 1991, Python supports multiple programming paradigms,including procedural, \n",
    "object-oriented, and functional programming. Its   extensive standard library and wide range of third-party packages make it \n",
    "ideal for various applications such as web development, data analysis, artificial intelligence, scientific computing,\n",
    "automation, and more. Python's user-friendly syntax emphasizes code readability, making it popular among beginners and\n",
    "professionals alike. It is open-source, has a large active community, and is widely used across industries for rapid \n",
    "development and problem-solving.'''\n",
    "\n",
    "answer2='''C is a general-purpose, procedural, high-level programming language used in the development of computer software and applications, system programming, games, and more.\n",
    "C language was developed by Dennis M. Ritchie at the Bell Telephone\n",
    "Laboratories in 1972.It is a powerful and flexible language which was first developed for the programming of the UNIX operating System.\n",
    "C is one of the most widely used programming languages.\n",
    "C programming language is known for its simplicity and efficiency. It is the best choice to start with programming as it gives you a foundational understanding of programming.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c036b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92cfaa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSA-based Similarity: 0.28632491905579277\n"
     ]
    }
   ],
   "source": [
    "#latent semantic similarity\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "def lsa_similarity(paragraph1, paragraph2):\n",
    "    \n",
    "    para1 = preprocess(paragraph1)\n",
    "    para2 = preprocess(paragraph2)\n",
    "    \n",
    "    \n",
    "    documents = [para1, para2]\n",
    "    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "    \n",
    "    # Apply LSA (Truncated SVD) to reduce dimensions\n",
    "    svd = TruncatedSVD(n_components=2)  # Reduce to 2 latent topics\n",
    "    lsa_matrix = svd.fit_transform(tfidf_matrix)\n",
    "    \n",
    "    \n",
    "    # Calculate the cosine similarity between the two paragraphs\n",
    "    similarity = cosine_similarity(lsa_matrix[0].reshape(1, -1), lsa_matrix[1].reshape(1, -1))\n",
    "\n",
    "    return similarity[0][0]\n",
    "similarity_score=lsa_similarity(preans,preans1 )\n",
    "print(f\"LSA-based Similarity: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dfe380b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Textual Similarity (BERT): 0.676443338394165\n"
     ]
    }
   ],
   "source": [
    "embedding1 = STS.encode(preans, convert_to_tensor=True)\n",
    "embedding2 = STS.encode(preans1,convert_to_tensor=True)\n",
    "\n",
    "# Step 2: Compute the cosine similarity between the embeddings\n",
    "similarity_score = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "print(f\"Semantic Textual Similarity (BERT): {similarity_score.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7faab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f685b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
